# -*- coding: utf-8 -*-
"""speech emotion detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12_vrtKnU_N6v3jxy9JEQsiR2a5WpWyYK
"""


# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/speech emotion detection/dataset
#%cd /dataset

"""## Import Libraries"""

import pandas as pd
import cv2
import os
import numpy as np
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
from scipy.io import wavfile
import librosa
import librosa.display
import IPython.display as ipd
import random
from patchify import patchify
from tensorflow.keras.applications import VGG19
from tqdm.notebook import tqdm
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input
from tensorflow.keras.models import Sequential
from keras.layers.core import Flatten, Dense, Dropout
from keras.layers.convolutional import Convolution1D,Convolution2D, MaxPooling2D, ZeroPadding2D,MaxPooling1D,ZeroPadding1D

"""## import data

>> this dataset is taken from the keggle which actually contain different voices of 24 actors representing different emotions. Here is the link for the dataset: [Click Here](https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition/data)
"""

# images = []
# images_name = []
# folders  =  list(os.listdir())

images = []
images_name = []
folders  =  []
for filename in os.listdir():
    if os.path.isdir(os.path.join(filename)):
        folders.append(filename)

#listing the folder names
folders = folders[:]
folders



"""# Reading Audio Images"""

for i in range(len(folders)):
    files = os.listdir(os.getcwd() + "/"+folders[i])
    files = [i for i in files if i.endswith('.wav')]

    for j in range(len(files)):
      images_name.append(folders[i]+"//"+files[j])

#reading all the spectograms images
images = []
for i in range(len(images_name)):
    images.append(cv2.imread(os.getcwd() +"dataset/Images/"+ images_name[i][:-3] +"png"))

images[0].shape

"""# Normalizing Data"""

images = np.array(images, dtype=np.float32) / 255
images.shape

"""# Reading the labels for the voice nodes's emotions"""

y = []
df = pd.DataFrame(columns=['Modality','Vocal channel','Emotion','Emotional intensity','Statement','Repetition','Actor'], index= range(len(images_name)))
for i in range(len(images_name)):
    split_list = images_name[i].split('-')
    split_list[-1] = split_list[-1][:2] 
    split_list[0] =  split_list[0][-2:]
    df.iloc[i] = split_list
    y.append(int(images_name[i].split('-')[2]))
df.drop(columns = ['Modality','Vocal channel','Emotion'], inplace = True)

obj_cols = df.loc[:, df.dtypes == np.object].columns
for col in obj_cols:
     df[col] = pd.to_numeric(df[col])

#one hot-encoding the labels
y = pd.get_dummies(y)

y.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.20,random_state=42)

pd.DataFrame(y_train).value_counts()

from tensorflow.keras import regularizers
from tensorflow.keras.layers import Masking




print("************* Defining the model ******************")


model1 = Sequential()

model1.add(ZeroPadding2D((1,1),input_shape=np.array(X_train)[0].shape))
model1.add(Convolution2D(8, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))
model1.add(ZeroPadding2D((1,1)))
model1.add(Convolution2D(8, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))
model1.add(MaxPooling2D((2,2),  padding='same'))
model1.add(Dropout(0.3))

model1.add(Convolution2D(64, 3, 3, activation='relu'))
model1.add(MaxPooling2D((2,2),  padding='same'))

model1.add(ZeroPadding2D((1,1)))
model1.add(Convolution2D(128, 3, 3, activation='relu'))

# model1.add(ZeroPadding2D((1,1)))
# model1.add(Convolution2D(128, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(l=0.1)))
# model1.add(Dropout(0.1))

model1.add(MaxPooling2D((2,2), padding='same'))


model1.add(Flatten())
model1.add(Dense(1024, activation='relu'))

model1.add(Dense(128, activation='relu'))

model1.add(Dense(8, activation='relu'))

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, Dropout, BatchNormalization


print("************* Defining another model ******************")

def build_deep_cnn(number_of_output, input_shape):
    
    model_cnn = keras.Sequential()
    model_cnn.add(Input(input_shape))
    
    model_cnn.add(Conv2D(32, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(Conv2D(32, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(MaxPooling2D(pool_size=(2,2)))
    model_cnn.add(Dropout(0.2))


    model_cnn.add(Conv2D(64, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(Conv2D(64, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(MaxPooling2D(pool_size=(2,2)))
    model_cnn.add(Dropout(0.3))


    model_cnn.add(Conv2D(128, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(Conv2D(128, kernel_size=(3,3), padding='same', activation="relu"))
    model_cnn.add(BatchNormalization())
    model_cnn.add(MaxPooling2D(pool_size=(2,2)))
    model_cnn.add(Dropout(0.4))


  
    model_cnn.add(Flatten())
    model_cnn.add(Dense(2048, activation='relu'))
    model_cnn.add(Dense(1024, activation='relu'))
    model_cnn.add(Dense(512, activation='relu'))

    #output layer for classification
    model_cnn.add(Dense(number_of_output, activation='softmax'))
    
    model_cnn.compile(optimizer= tf.optimizers.Adam(),
                      loss=keras.losses.categorical_crossentropy,
                      metrics='accuracy')
    return model_cnn


print("\n************* compiling and training the model ******************")

input_shape = images[0].shape
number_of_output = 8
model = build_deep_cnn(number_of_output=number_of_output, input_shape=input_shape)
model.summary()

h = model.fit(X_train, y_train,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test), batch_size=20)


print("\n************* Evaluating the model ******************")

plt.figure(figsize=(8,5))
plt.plot(h.history['accuracy'])
plt.plot(h.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()



plt.figure(figsize=(8,5))
plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

y_test

y_pred = model.predict(X_test)
y_test2 = []
y_pred2 = []
for i in range(len(y_test)):
    y_pred2.append(np.argmax(y_pred[i]))
    y_test2.append(np.argmax(y_test[i]))

from sklearn.metrics import accuracy_score
print("Accuracy =",accuracy_score(y_pred2,y_test2) * 100)

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(y_test2,y_pred2))

