{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"driver_plate_identify.ipynb","provenance":[],"mount_file_id":"1i185RbAdr3oLRJi_TKf-aU2NpaWXqhcQ","authorship_tag":"ABX9TyNLok8nh8R50DocHYj8MUVw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!sudo apt install tesseract-ocr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTkq_5Gi6gjl","executionInfo":{"status":"ok","timestamp":1657919919611,"user_tz":-300,"elapsed":9940,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"d718e413-2b98-4e84-cfc1-a9e6bc43e186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 4,795 kB of archives.\n","After this operation, 15.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n","Fetched 4,795 kB in 4s (1,133 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 155653 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n","Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["!pip install facenet_pytorch==0.1.0\n","!pip install pytesseract"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"RgeQO56eKf6V","executionInfo":{"status":"ok","timestamp":1658005069320,"user_tz":-300,"elapsed":9832,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"c3838259-7d60-45f7-d27b-5e8c1928ef50"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet_pytorch==0.1.0\n","  Downloading facenet_pytorch-0.1.0-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 25.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch==0.1.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch==0.1.0) (1.21.6)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch==0.1.0) (4.1.2.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch==0.1.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch==0.1.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch==0.1.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch==0.1.0) (3.0.4)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-0.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n","Collecting Pillow>=8.0.0\n","  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 46.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n","Installing collected packages: Pillow, pytesseract\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Pillow-9.2.0 pytesseract-0.3.9\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/driver_plate_identify"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgvFpP05KbmI","executionInfo":{"status":"ok","timestamp":1657968216904,"user_tz":-300,"elapsed":467,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"bdf63211-91d4-4d16-c58e-28f5bb13ddc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/driver_plate_identify\n"]}]},{"cell_type":"code","source":["DRIVER_PATH = 'Driver_dataset'\n","MODEL_DIR_PATH = 'model'\n","MODEL_PATH = 'model/face_recogniser.pkl'"],"metadata":{"id":"tWrKTaDcKn7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"74XmpFUhI1KB","executionInfo":{"status":"ok","timestamp":1658005083356,"user_tz":-300,"elapsed":1430,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}}},"outputs":[],"source":["import os\n","from collections import namedtuple\n","import torch\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","from torchvision import transforms, datasets\n","from facenet_pytorch.models.utils.detect_face import extract_face\n","from PIL import Image, ImageDraw, ImageFont\n","import joblib\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import metrics"]},{"cell_type":"code","source":["class FaceFeaturesExtractor:\n","    def __init__(self):\n","        self.aligner = MTCNN(prewhiten=False, keep_all=True, thresholds=[0.6, 0.7, 0.9])\n","        self.facenet_preprocess = transforms.Compose([Whitening()])\n","        self.facenet = InceptionResnetV1(pretrained='vggface2').eval()\n","\n","    def extract_features(self, img):\n","        bbs, _ = self.aligner.detect(img)\n","        if bbs is None:\n","            # if no face is detected\n","            return None, None\n","\n","        faces = torch.stack([extract_face(img, bb) for bb in bbs])\n","        embeddings = self.facenet(self.facenet_preprocess(faces)).detach().numpy()\n","\n","        return bbs, embeddings\n","\n","    def __call__(self, img):\n","        return self.extract_features(img)"],"metadata":{"id":"pVBHZLQWJEbY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exif_orientation_tag = 0x0112\n","exif_transpose_sequences = [  # Val  0th row  0th col\n","    [],  # 0    (reserved)\n","    [],  # 1   top      left\n","    [Image.FLIP_LEFT_RIGHT],  # 2   top      right\n","    [Image.ROTATE_180],  # 3   bottom   right\n","    [Image.FLIP_TOP_BOTTOM],  # 4   bottom   left\n","    [Image.FLIP_LEFT_RIGHT, Image.ROTATE_90],  # 5   left     top\n","    [Image.ROTATE_270],  # 6   right    top\n","    [Image.FLIP_TOP_BOTTOM, Image.ROTATE_90],  # 7   right    bottom\n","    [Image.ROTATE_90],  # 8   left     bottom\n","]\n","\n","\n","class ExifOrientationNormalize(object):\n","    \"\"\"\n","    Normalizes rotation of the image based on exif orientation info (if exists.)\n","    \"\"\"\n","\n","    def __call__(self, img):\n","        if 'parsed_exif' in img.info and exif_orientation_tag in img.info['parsed_exif']:\n","            orientation = img.info['parsed_exif'][exif_orientation_tag]\n","            transposes = exif_transpose_sequences[orientation]\n","            for trans in transposes:\n","                img = img.transpose(trans)\n","        return img\n","\n","\n","class Whitening(object):\n","    \"\"\"\n","    Whitens the image.\n","    \"\"\"\n","\n","    def __call__(self, img):\n","        mean = img.mean()\n","        std = img.std()\n","        std_adj = std.clamp(min=1.0 / (float(img.numel()) ** 0.5))\n","        y = (img - mean) / std_adj\n","        return y"],"metadata":{"id":"o66pjUSzJR6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657968155154,"user_tz":-300,"elapsed":686,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"fcf45c13-3e4b-4cad-dd58-ee8f72946975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: ROTATE_180 is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.ROTATE_180 instead.\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: FLIP_TOP_BOTTOM is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_TOP_BOTTOM instead.\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: ROTATE_90 is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.ROTATE_90 instead.\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: ROTATE_270 is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.ROTATE_270 instead.\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: FLIP_TOP_BOTTOM is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_TOP_BOTTOM instead.\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: ROTATE_90 is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.ROTATE_90 instead.\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: ROTATE_90 is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.ROTATE_90 instead.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}]},{"cell_type":"code","source":["# Only some parts are being used\n","\n","Prediction = namedtuple('Prediction', 'label confidence')\n","Face = namedtuple('Face', 'top_prediction bb all_predictions')\n","BoundingBox = namedtuple('BoundingBox', 'left top right bottom')\n","\n","\n","def top_prediction(idx_to_class, probs):\n","    top_label = probs.argmax()\n","    return Prediction(label=idx_to_class[top_label], confidence=probs[top_label])\n","\n","\n","def to_predictions(idx_to_class, probs):\n","    return [Prediction(label=idx_to_class[i], confidence=prob) for i, prob in enumerate(probs)]\n","\n","\n","class FaceRecogniser:\n","    def __init__(self, feature_extractor, classifier, idx_to_class):\n","        self.feature_extractor = feature_extractor\n","        self.classifier = classifier\n","        self.idx_to_class = idx_to_class\n","\n","    def recognise_faces(self, img):\n","        bbs, embeddings = self.feature_extractor(img)\n","        if bbs is None:\n","            # if no faces are detected\n","            return []\n","\n","        predictions = self.classifier.predict_proba(embeddings)\n","\n","        return [\n","            Face(\n","                top_prediction=top_prediction(self.idx_to_class, probs),\n","                bb=BoundingBox(left=bb[0], top=bb[1], right=bb[2], bottom=bb[3]),\n","                all_predictions=to_predictions(self.idx_to_class, probs)\n","            )\n","            for bb, probs in zip(bbs, predictions)\n","        ]\n","\n","    def __call__(self, img):\n","        return self.recognise_faces(img)"],"metadata":{"id":"qSA9w61FOj5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_to_embeddings(dataset, features_extractor):\n","    transform = transforms.Compose([\n","        ExifOrientationNormalize(),\n","        transforms.Resize(1024)\n","    ])\n","\n","    embeddings = []\n","    labels = []\n","    for img_path, label in dataset.samples:\n","        print(img_path)\n","        _, embedding = features_extractor(transform(Image.open(img_path).convert('RGB')))\n","        if embedding is None:\n","            print(\"Could not find face on {}\".format(img_path))\n","            continue\n","        if embedding.shape[0] > 1:\n","            print(\"Multiple faces detected for {}, taking one with highest probability\".format(img_path))\n","            embedding = embedding[0, :]\n","        embeddings.append(embedding.flatten())\n","        labels.append(label)\n","\n","    return np.stack(embeddings), labels"],"metadata":{"id":"8fEccTvULUAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(features_extractor):\n","    dataset = datasets.ImageFolder(DRIVER_PATH)\n","    embeddings, labels = dataset_to_embeddings(dataset, features_extractor)\n","    return embeddings, labels, dataset.class_to_idx"],"metadata":{"id":"YZTctb82KGqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(embeddings, labels):\n","    softmax = LogisticRegression(solver='lbfgs', multi_class='multinomial', C=10, max_iter=10000)\n","    clf = softmax\n","    clf.fit(embeddings, labels)\n","\n","    return clf"],"metadata":{"id":"8yGal5qzLoUq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def draw_bb_on_img(faces, img):\n","    draw = ImageDraw.Draw(img)\n","    fs = max(20, round(img.size[0] * img.size[1] * 0.000005))\n","    font = ImageFont.truetype('fonts/font.ttf', fs)\n","    margin = 5\n","\n","    for face in faces:\n","        text = \"%s %.2f%%\" % (face.top_prediction.label.upper(), face.top_prediction.confidence * 100)\n","        text_size = font.getsize(text)\n","\n","        # bounding box\n","        draw.rectangle(\n","            (\n","                (int(face.bb.left), int(face.bb.top)),\n","                (int(face.bb.right), int(face.bb.bottom))\n","            ),\n","            outline='green',\n","            width=2\n","        )\n","\n","        # text background\n","        draw.rectangle(\n","            (\n","                (int(face.bb.left - margin), int(face.bb.bottom) + margin),\n","                (int(face.bb.left + text_size[0] + margin), int(face.bb.bottom) + text_size[1] + 3 * margin)\n","            ),\n","            fill='black'\n","        )\n","\n","        # text\n","        draw.text(\n","            (int(face.bb.left), int(face.bb.bottom) + 2 * margin),\n","            text,\n","            font=font\n","        )\n","    return draw"],"metadata":{"id":"mv0pvSAmjbOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features_extractor = FaceFeaturesExtractor()\n","embeddings, labels, class_to_idx = load_data(features_extractor)\n","clf = train(embeddings, labels)\n","\n","idx_to_class = {v: k for k, v in class_to_idx.items()}\n","\n","target_names = map(lambda i: i[1], sorted(idx_to_class.items(), key=lambda i: i[0]))\n","print(metrics.classification_report(labels, clf.predict(embeddings), target_names=list(target_names)))\n","\n","if not os.path.isdir(MODEL_DIR_PATH):\n","    os.mkdir(MODEL_DIR_PATH)\n","model_path = os.path.join('model', 'face_recogniser.pkl')\n","joblib.dump(FaceRecogniser(features_extractor, clf, idx_to_class), model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2QkE2NJJ_zW","executionInfo":{"status":"ok","timestamp":1657921294565,"user_tz":-300,"elapsed":30559,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"259da829-2546-4783-b58d-55722eee11ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Driver_dataset/Abdul_Hanan/Abdul Hanan.jpg\n","Driver_dataset/Abdullah_Anas/Abdullah Anas.jpg\n","Driver_dataset/Abdullah_Ramzan/Abdullah Ramzan.jpeg\n","Driver_dataset/Abdur_Rafay/Abdur Rafay.jpeg\n","Driver_dataset/Ahmad_Ashraf/Ahmad Ashraf.jpg\n","Driver_dataset/Aiza_Ali/Aiza Ali.jpeg\n","Driver_dataset/Amina_Habib/Amina Habib.jpeg\n","Driver_dataset/Amir_Arsalan/Amir Arsalan.jpg\n","Driver_dataset/Arsalan_Waqas/Arsalan Waqas.jpeg\n","Driver_dataset/Asghar_Ismail/Asghar Ismail.jpg\n","Driver_dataset/Asif_Ali/Asif Ali.jpg\n","Multiple faces detected for Driver_dataset/Asif_Ali/Asif Ali.jpg, taking one with highest probability\n","Driver_dataset/Asim_Raheel/Asim Raheel.jpg\n","Driver_dataset/Haroon_Yousaf/Haroon Yousaf.jpg\n","Driver_dataset/Hassan_Munir/Hassan Munir.jpeg\n","Driver_dataset/Iqra_Mubeen/Iqra Mubeen.jpeg\n","Driver_dataset/Misbah_Kiran/Misbah Kiran.jpeg\n","Driver_dataset/Momena_Khalil/Momena Khalil.jpeg\n","Driver_dataset/Momin_Shehzad/Momin Shehzad.jpg\n","Driver_dataset/Muaaz_Tehami/Muaaz Tehami.jpg\n","Driver_dataset/Muhammad_Anas/Muhammad Anas.jpg\n","Driver_dataset/Muhammad_Majid/Muhammad Majid.jpg\n","Driver_dataset/Muhammad_Usman/Muhammad Usman.jpeg\n","Multiple faces detected for Driver_dataset/Muhammad_Usman/Muhammad Usman.jpeg, taking one with highest probability\n","Driver_dataset/Muhammad_Zaeem/Muhammad Zaeem.jpeg\n","Driver_dataset/Murwa_Malik/Murwa Malik.jpg\n","Driver_dataset/Naveed_Baloach/Naveed Baloach.jpg\n","Driver_dataset/Nida_Ismail/Nida Ismail.jpeg\n","Driver_dataset/Rabael_Hina/Rabael Hina.jpeg\n","Driver_dataset/Rafay_Sultan/Rafay Sultan.jpg\n","Driver_dataset/Samreen_Badar/Samreen Badar.jpeg\n","Driver_dataset/Sana_Asghar/Sana Asghar.jpeg\n","Driver_dataset/Sanaye_Muhammad/Sanaye Muhammad.jpg\n","Driver_dataset/Shahbaz_Vohra/Shahbaz Vohra.jpeg\n","Driver_dataset/Shehryar_Nadeem/Shehryar Nadeem.jpg\n","Driver_dataset/Talha_Tariq/Talha Tariq.jpeg\n","Driver_dataset/Tayyab_Javed/Tayyab Javed.jpeg\n","Driver_dataset/Ume_Aimen/Ume Aimen.jpeg\n","Driver_dataset/Umme_Zainab/Umme Zainab.jpeg\n","Driver_dataset/Usama_Ahmad/Usama Ahmad.jpeg\n","Driver_dataset/Usman_Fahad/Usman Fahad.jpg\n","Driver_dataset/Warda_Mehmood/Warda Mehmood.jpeg\n","Driver_dataset/Zaara_Kamran/Zaara Kamran.jpeg\n","Driver_dataset/Zainab_Ejaz/Zainab Ejaz.jpeg\n","Driver_dataset/Zunair_Zafar/Zunair Zafar.jpeg\n","                 precision    recall  f1-score   support\n","\n","    Abdul_Hanan       1.00      1.00      1.00         1\n","  Abdullah_Anas       1.00      1.00      1.00         1\n","Abdullah_Ramzan       1.00      1.00      1.00         1\n","    Abdur_Rafay       1.00      1.00      1.00         1\n","   Ahmad_Ashraf       1.00      1.00      1.00         1\n","       Aiza_Ali       1.00      1.00      1.00         1\n","    Amina_Habib       1.00      1.00      1.00         1\n","   Amir_Arsalan       1.00      1.00      1.00         1\n","  Arsalan_Waqas       1.00      1.00      1.00         1\n","  Asghar_Ismail       1.00      1.00      1.00         1\n","       Asif_Ali       1.00      1.00      1.00         1\n","    Asim_Raheel       1.00      1.00      1.00         1\n","  Haroon_Yousaf       1.00      1.00      1.00         1\n","   Hassan_Munir       1.00      1.00      1.00         1\n","    Iqra_Mubeen       1.00      1.00      1.00         1\n","   Misbah_Kiran       1.00      1.00      1.00         1\n","  Momena_Khalil       1.00      1.00      1.00         1\n","  Momin_Shehzad       1.00      1.00      1.00         1\n","   Muaaz_Tehami       1.00      1.00      1.00         1\n","  Muhammad_Anas       1.00      1.00      1.00         1\n"," Muhammad_Majid       1.00      1.00      1.00         1\n"," Muhammad_Usman       1.00      1.00      1.00         1\n"," Muhammad_Zaeem       1.00      1.00      1.00         1\n","    Murwa_Malik       1.00      1.00      1.00         1\n"," Naveed_Baloach       1.00      1.00      1.00         1\n","    Nida_Ismail       1.00      1.00      1.00         1\n","    Rabael_Hina       1.00      1.00      1.00         1\n","   Rafay_Sultan       1.00      1.00      1.00         1\n","  Samreen_Badar       1.00      1.00      1.00         1\n","    Sana_Asghar       1.00      1.00      1.00         1\n","Sanaye_Muhammad       1.00      1.00      1.00         1\n","  Shahbaz_Vohra       1.00      1.00      1.00         1\n","Shehryar_Nadeem       1.00      1.00      1.00         1\n","    Talha_Tariq       1.00      1.00      1.00         1\n","   Tayyab_Javed       1.00      1.00      1.00         1\n","      Ume_Aimen       1.00      1.00      1.00         1\n","    Umme_Zainab       1.00      1.00      1.00         1\n","    Usama_Ahmad       1.00      1.00      1.00         1\n","    Usman_Fahad       1.00      1.00      1.00         1\n","  Warda_Mehmood       1.00      1.00      1.00         1\n","   Zaara_Kamran       1.00      1.00      1.00         1\n","    Zainab_Ejaz       1.00      1.00      1.00         1\n","   Zunair_Zafar       1.00      1.00      1.00         1\n","\n","       accuracy                           1.00        43\n","      macro avg       1.00      1.00      1.00        43\n","   weighted avg       1.00      1.00      1.00        43\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['model/face_recogniser.pkl']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["image_path = '/content/drive/MyDrive/driver_plate_identify/Driver_dataset/Abdullah_Anas/Abdullah Anas.jpg'\n","\n","preprocess = ExifOrientationNormalize()\n","img = Image.open(image_path)\n","filename = img.filename\n","img = preprocess(img)\n","img = img.convert('RGB')\n","\n","faces = joblib.load(MODEL_PATH)(img)\n","if faces:\n","  print('The face is of: ', faces[0].top_prediction.label.upper())\n","  print('The prediction precentage is: ', faces[0].top_prediction.confidence * 100)\n","\n","if not faces:\n","    print('No faces found in this image.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0pOfT4IQoBA","executionInfo":{"status":"ok","timestamp":1657968227491,"user_tz":-300,"elapsed":2323,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"eb384f7d-2e4c-428b-ae7d-c96332c54ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The face is of:  ABDULLAH_ANAS\n","The prediction precentage is:  27.85427870798222\n"]}]},{"cell_type":"markdown","source":["## Number plate detection"],"metadata":{"id":"1tEuY3H1sPL-"}},{"cell_type":"code","source":["import pytesseract\n","import cv2"],"metadata":{"id":"sUHUDTjgsOFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(text):\n","\t# strip out non-ASCII text so we can draw the text on the image\n","  # using OpenCV\n","  text = text.replace('\\n', ' ')\n","  return \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()"],"metadata":{"id":"NCG37UDb0h4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = cv2.imread('/content/drive/MyDrive/driver_plate_identify/Number_Plate_dataset/Abdul Hanan.jpeg',cv2.IMREAD_COLOR)\n","text = pytesseract.image_to_string(img, config='-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 --psm 11')"],"metadata":{"id":"l-G0Od9A58Fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rlSXasyK7CcB","executionInfo":{"status":"ok","timestamp":1657739185885,"user_tz":-300,"elapsed":13,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"0104fa9d-e024-4524-cdc6-519e972f6f43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ICT-ISLAMABAD\\n\\nAVS:822)\\n\\x0c'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["cleanup_text(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"n3fkmkpt6qVY","executionInfo":{"status":"ok","timestamp":1657739186968,"user_tz":-300,"elapsed":14,"user":{"displayName":"Shaharyar Sajid","userId":"16055519587786193506"}},"outputId":"4b98d661-08fc-42e9-a498-820f148fff55"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ICT-ISLAMABAD  AVS:822)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":62}]}]}